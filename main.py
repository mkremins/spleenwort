from clingo.control import Control
from clingo.symbol import SymbolType
from openai import OpenAI

### Clingo/ASP functionality

def exprify_symbol(sym):
  if sym.type == SymbolType.Number:
    return sym.number
  elif sym.type == SymbolType.String:
    return sym.string
  elif sym.type == SymbolType.Function and len(sym.arguments) == 0:
    return sym.name
  elif sym.type == SymbolType.Function:
    return [sym.name, *[exprify_symbol(arg) for arg in sym.arguments]]
  else:
    raise ["BAD SYMBOL", sym]

def generate_outlines():
  # helper callback to collect valid story outlines as they're generated
  all_outlines = []
  def collect_outline(model):
    # get shown symbols from the model and translate them to lispy exprs
    syms = model.symbols(shown=True)
    exprs = [exprify_symbol(sym) for sym in syms]
    # assume all exprs are of the form ["scene_performs_function", idx, fn];
    # extract a story outline consisting of fns sorted by idx
    exprs.sort(key=lambda expr: expr[1])
    outline = [expr[2] for expr in exprs]
    all_outlines.append(outline)
    print(outline)
  # invoke clingo to start solving
  ctl = Control()
  ctl.configuration.solve.models = 0 # enumerate all models
  ctl.load("./plotgen.lp")
  ctl.ground()
  ctl.solve(on_model=collect_outline, on_unsat=lambda: print("UNSAT"))
  # when clingo finishes, return collected outlines
  return all_outlines

### OpenAI/LLM functionality

oai_api_key = open("openai_api_key.txt").read()
oai_client = OpenAI(api_key=oai_api_key)

# outline-based story generation: translate an ASP-generated outline
# and a brief user input text into a sequence of LLM prompts

init_prompt = """
I'm trying to write a story. Here's some notes on what I want it to be about:

{{user_input_text}}

Write the first paragraph of the story. In this paragraph, {{follow_instruction}}.
""".strip()

followup_prompt = """
Write the next paragraph of the story. In this paragraph, {{follow_instruction}}.
""".strip()

instructions_by_function = {
  "introduce_character":
    "introduce a new character",
  "complicate_relationship_between_characters":
    "complicate the relationship between two previously introduced characters",
  "remove_character":
    "write a previously introduced character out of the story",
  "make_reader_sad":
    "write something that conveys an atmosphere of sadness",
  "make_reader_angry":
    "write something that conveys an atmosphere of happiness",
  "make_reader_angry":
    "write something that conveys an atmosphere of anger",
  "end_the_story":
    "bring the story to a conclusion",
}

def promptify_outline(outline, user_input_text):
  prompts = []
  for i in range(len(outline)):
    is_first_paragraph = i == 0
    function = outline[i]
    instruction = instructions_by_function[function]
    prompt_template = init_prompt if is_first_paragraph else followup_prompt
    prompt = prompt_template.replace("{{follow_instruction}}", instruction)
    if is_first_paragraph:
      prompt = prompt.replace("{{user_input_text}}", user_input_text)
    prompts.append(prompt)
  return prompts

# naive baseline story generation: translate a number of paragraphs
# and a brief user input text into a sequence of LLM prompts

naive_init_prompt = """
I'm trying to write a story. Here's some notes on what I want it to be about:

{{user_input_text}}

Write the first paragraph of the story.
""".strip()

naive_followup_prompt = """
Write the next paragraph of the story.
""".strip()

def promptify_naively(num_paras, user_input_text):
  prompts = []
  for i in range(num_paras):
    is_first_paragraph = i == 0
    function = outline[i]
    instruction = instructions_by_function[function]
    prompt = naive_init_prompt if is_first_paragraph else naive_followup_prompt
    if is_first_paragraph:
      prompt = prompt.replace("{{user_input_text}}", user_input_text)
    prompts.append(prompt)
  return prompts

# run a sequence of LLM prompts generated by one of the above approaches,
# and extract the finished story from the LLM responses

def storify_prompts(prompts):
  # translate a sequence of LLM prompts into a story
  messages = []
  for prompt in prompts:
    # prompt the LLM for the next paragraph
    messages.append({"role": "user", "content": prompt})
    completion = oai_client.chat.completions.create(
      messages=messages, model="gpt-3.5-turbo"
    )
    # append response message as context for future paragraphs
    paragraph = completion.choices[0].message.content
    messages.append({"role": "assistant", "content": paragraph})
    print(paragraph + "\n")
  # parse story out of messages
  paragraphs = [msg["content"] for msg in messages if msg["role"] == "assistant"]
  return "\n\n".join(paragraphs)

### tie it all together

# generate story outlines
outlines = generate_outlines()
print(outlines)

# storify an outline
print("### OUTLINE")
outline = outlines[0] # TODO pick at random?
print(outline)
user_input_text = "cat pirates"
outline_prompts = promptify_outline(outline, user_input_text)
storify_prompts(outline_prompts)

# storify naively (same number of paragraphs)
print("### NAIVE")
naive_prompts = promptify_naively(len(outline), user_input_text)
storify_prompts(naive_prompts)
